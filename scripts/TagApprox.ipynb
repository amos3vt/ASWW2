{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()\n",
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use tags with spaces?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"space\" # Set to \"space\" or \"nospace\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tag data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tag data\n",
    "transcriber_tags = pd.read_excel(\"../data/tags.xlsx\", converters={column:str}, sheet_name=\"ZooniverseTags\")\n",
    "expert_tags = pd.read_excel(\"../data/tags.xlsx\", converters={column:str}, sheet_name=\"ExpertTags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print (some) tags that Word2Vec does not understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of these tags are short phrases which Word2Vec does not have in its base vocabulary. I do not currently have the resources to fine-tune Word2Vec to add these phrases. For this reason, the current version of this notebook only compares BERT tag embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in expert_tags[column]:\n",
    "    try:\n",
    "        wv[e]\n",
    "    except Exception as err:\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine best approximations for transcriber tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Redefine encoding function to allow progress tracking\n",
    "count = 0\n",
    "def encode(tag):\n",
    "    global count\n",
    "    if count%500 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    return bc.encode([tag])[0]\n",
    "\n",
    "# Get embeddings\n",
    "expert_embed = [encode(i) for i in expert_tags[column]]\n",
    "transcriber_embed = [encode(i) for i in transcriber_tags[column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare transcriber tag at index i to all expert tags\n",
    "def compare_all(i):\n",
    "    \n",
    "    # Track best results\n",
    "    result = {\n",
    "        \"index\": i,\n",
    "        \"transcriber_tag\": transcriber_tags['nospace'].iloc[i],\n",
    "        \"expert_tag_1\": None,\n",
    "        \"score_1\": -1,\n",
    "        \"expert_tag_2\": None,\n",
    "        \"score_2\": -1,\n",
    "        \"expert_tag_3\": None,\n",
    "        \"score_3\": -1\n",
    "    }\n",
    "    \n",
    "    # Make comparisons\n",
    "    for j in range(len(expert_tags)):\n",
    "        score = np.dot(transcriber_embed[i], expert_embed[j]) / \\\n",
    "            (np.linalg.norm(transcriber_embed[i]) * np.linalg.norm(expert_embed[j]))\n",
    "        if score > result['score_1']:\n",
    "            result['expert_tag_1'] = expert_tags[column].iloc[j]\n",
    "            result['score_1'] = score\n",
    "        elif score > result['score_2']:\n",
    "            result['expert_tag_2'] = expert_tags[column].iloc[j]\n",
    "            result['score_2'] = score\n",
    "        elif score > result['score_3']:\n",
    "            result['expert_tag_3'] = expert_tags[column].iloc[j]\n",
    "            result['score_3'] = score\n",
    "            \n",
    "    return result\n",
    "\n",
    "results = [compare_all(i) for i in range(len(transcriber_tags))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write results to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of results to dataframe\n",
    "df = pd.DataFrame(results)\n",
    "# Sort results by cosine similarity\n",
    "df = df.sort_values('score_1', ascending=False)\n",
    "# Write to excel file\n",
    "df.to_excel(\"../data/tag_approx_\"+column+\".xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster words that lack a close-enough approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform KMeans on embeddings with low similarity scores\n",
    "k = 30 # Adjust number of clusters\n",
    "\n",
    "cluster_results = [results[i] for i in range(len(results))\n",
    "                   if results[i]['score_1_bert'] < 0.75 ] # Adjust similarity threshold\n",
    "\n",
    "cluster_embeds = [transcriber_embed[cluster_results[i]['index']] \n",
    "                  for i in range(len(cluster_results))]\n",
    "\n",
    "kmeans = KMeans(n_clusters=k).fit(cluster_embeds)\n",
    "\n",
    "for i in range(k):\n",
    "    print(\"Cluster\", i)\n",
    "    print([cluster_results[j]['transcriber_tag'] \n",
    "           for j in range(len(kmeans.labels_))\n",
    "           if kmeans.labels_[j] == i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
