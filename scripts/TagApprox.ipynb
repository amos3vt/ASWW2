{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use tags with spaces?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"space\" # Set to \"space\" or \"nospace\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tag data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tag data\n",
    "transcriber_tags = pd.read_excel(\"../data/tags.xlsx\", converters={column:str}, sheet_name=\"ZooniverseTags\")\n",
    "expert_tags = pd.read_excel(\"../data/tags.xlsx\", converters={column:str}, sheet_name=\"ExpertTags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine best approximations for transcriber tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Consider adding spaces to multi-word tags\n",
    "- Word2Vec does not recognize some tags, so I'm just using BERT for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "# Redefine encoding function to allow progress tracking\n",
    "count = 0\n",
    "def encode(tag):\n",
    "    global count\n",
    "    if count%500 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    return bc.encode([tag])[0]\n",
    "\n",
    "# Get embeddings\n",
    "expert_embed = [encode(i) for i in expert_tags[column]]\n",
    "transcriber_embed = [encode(i) for i in transcriber_tags[column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare transcriber tag at index i to all expert tags\n",
    "def compare_all(i):\n",
    "    \n",
    "    # Track best results\n",
    "    result = {\n",
    "        \"index\": i,\n",
    "        \"transcriber_tag\": transcriber_tags[column].iloc[i],\n",
    "        \"expert_tag_1_bert\": None,\n",
    "        \"score_1_bert\": -1,\n",
    "        \"expert_tag_2_bert\": None,\n",
    "        \"score_2_bert\": -1,\n",
    "        \"expert_tag_3_bert\": None,\n",
    "        \"score_3_bert\": -1\n",
    "    }\n",
    "    \n",
    "    # Make comparisons\n",
    "    for j in range(len(expert_tags)):\n",
    "        score = np.dot(transcriber_embed[i], expert_embed[j]) / \\\n",
    "            (np.linalg.norm(transcriber_embed[i]) * np.linalg.norm(expert_embed[j]))\n",
    "        if score > result['score_1_bert']:\n",
    "            result['expert_tag_1_bert'] = expert_tags[column].iloc[j]\n",
    "            result['score_1_bert'] = score\n",
    "        elif score > result['score_2_bert']:\n",
    "            result['expert_tag_2_bert'] = expert_tags[column].iloc[j]\n",
    "            result['score_2_bert'] = score\n",
    "        elif score > result['score_3_bert']:\n",
    "            result['expert_tag_3_bert'] = expert_tags[column].iloc[j]\n",
    "            result['score_3_bert'] = score\n",
    "            \n",
    "    return result\n",
    "\n",
    "results = [compare_all(i) for i in range(len(transcriber_tags))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write results to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of results to dataframe\n",
    "df = pd.DataFrame(results)\n",
    "# Sort results by cosine similarity\n",
    "df = df.sort_values('score_1_bert', ascending=False)\n",
    "# Write to excel file\n",
    "df.to_excel(\"../data/tag_approx_\"+column+\".xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster words that lack a close-enough approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform KMeans on embeddings with low similarity scores\n",
    "k = 30\n",
    "\n",
    "cluster_results = [results[i] for i in range(len(results))\n",
    "                   if results[i]['score_1_bert'] < 0.75 ]\n",
    "\n",
    "cluster_embeds = [transcriber_embed[cluster_results[i]['index']] \n",
    "                  for i in range(len(cluster_results))]\n",
    "\n",
    "kmeans = KMeans(n_clusters=k).fit(cluster_embeds)\n",
    "\n",
    "for i in range(k):\n",
    "    print(\"Cluster\", i)\n",
    "    print([cluster_results[j]['transcriber_tag'] \n",
    "           for j in range(len(kmeans.labels_))\n",
    "           if kmeans.labels_[j] == i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
