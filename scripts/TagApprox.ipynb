{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use tags with spaces?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"space\" # Set to \"space\" or \"nospace\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tag data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tag data\n",
    "transcriber_tags = pd.read_excel(\"../data/tags.xlsx\", converters={column:str}, sheet_name=\"ZooniverseTags\")\n",
    "expert_tags = pd.read_excel(\"../data/tags.xlsx\", converters={column:str}, sheet_name=\"ExpertTags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine best approximations for transcriber tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Consider adding spaces to multi-word tags\n",
    "- Word2Vec does not recognize some tags, so I'm just using BERT for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n"
     ]
    }
   ],
   "source": [
    "# Redefine encoding function to allow progress tracking\n",
    "count = 0\n",
    "def encode(tag):\n",
    "    global count\n",
    "    if count%500 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    return bc.encode([tag])[0]\n",
    "\n",
    "# Get embeddings\n",
    "expert_embed = [encode(i) for i in expert_tags[column]]\n",
    "transcriber_embed = [encode(i) for i in transcriber_tags[column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare transcriber tag at index i to all expert tags\n",
    "def compare_all(i):\n",
    "    \n",
    "    # Track best results\n",
    "    result = {\n",
    "        \"index\": i,\n",
    "        \"transcriber_tag\": transcriber_tags[column].iloc[i],\n",
    "        \"best_expert_tag_bert\": None,\n",
    "        \"best_score_bert\": -1,\n",
    "        \"best_expert_tag_w2v\": None,\n",
    "        \"best_score_w2v\": -1\n",
    "    }\n",
    "    \n",
    "    # Make comparisons\n",
    "    for j in range(len(expert_tags)):\n",
    "        score = np.dot(transcriber_embed[i], expert_embed[j]) / \\\n",
    "            (np.linalg.norm(transcriber_embed[i]) * np.linalg.norm(expert_embed[j]))\n",
    "        if score > result['best_score_bert']:\n",
    "            result['best_expert_tag_bert'] = expert_tags[column].iloc[j]\n",
    "            result['best_score_bert'] = score\n",
    "            \n",
    "    return result\n",
    "\n",
    "results = [compare_all(i) for i in range(len(transcriber_tags))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write results to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of results to dataframe\n",
    "df = pd.DataFrame(results)\n",
    "# Sort results by cosine similarity\n",
    "df = df.sort_values('best_score_bert', ascending=False)\n",
    "# Write to excel file\n",
    "df.to_excel(\"../data/tag_approx_\"+column+\".xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster words that lack a close-enough approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "['fayetteville', 'guadalcanal', 'mojave', 'negros', 'ranches', 'rommel']\n",
      "Cluster 1\n",
      "['get it over with', 'get them out of here', 'give what you get', 'hell of a deal', 'just do your job', 'make the best of it']\n",
      "Cluster 2\n",
      "['bff', 'ww1', 'ww2', 'x1186']\n",
      "Cluster 3\n",
      "['bayonet', 'gi bill of rights', 'great depression', 'great depression has ended', 'length of service', 'port of embarkation', 'post world war']\n",
      "Cluster 4\n",
      "['amen', 'close-by', 'commonsense', 'cpn', 'europeantheater', 'illegible', 'marginalia', 'on par', 'unassigned']\n",
      "Cluster 5\n",
      "['hooah', 'whatsnext']\n"
     ]
    }
   ],
   "source": [
    "# Perform KMeans on embeddings with low similarity scores\n",
    "k = 6\n",
    "\n",
    "cluster_results = [results[i] for i in range(len(results))\n",
    "                   if results[i]['best_score_bert'] < 0.6 ]\n",
    "\n",
    "cluster_embeds = [transcriber_embed[cluster_results[i]['index']] \n",
    "                  for i in range(len(cluster_results))]\n",
    "\n",
    "kmeans = KMeans(n_clusters=k).fit(cluster_embeds)\n",
    "\n",
    "for i in range(k):\n",
    "    print(\"Cluster\", i)\n",
    "    print([cluster_results[j]['transcriber_tag'] \n",
    "           for j in range(len(kmeans.labels_))\n",
    "           if kmeans.labels_[j] == i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
