{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the Interest of a Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: Score responses by how interesting they may be.\n",
    "\n",
    "**Properties of an Interesting Response (for our purposes)**:\n",
    "- greater length\n",
    "- variation of ideas (not paraphrasing the same sentences repeatedly)\n",
    "- discussion of certain topics\n",
    "  - race\n",
    "  - gender\n",
    "  - combat\n",
    "  - training\n",
    "- lack of discussion of certain topics\n",
    "  - general comments about the survey itself\n",
    "- clarity of response\n",
    "  - few \"unclear\" tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"interest_training.xlsx\" file contains a curated sample of responses from multiple surveys which we will use to develop a model for scoring how \"interesting\" a response is overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Survey data\n",
    "path = \"../data/interest_training.xlsx\"\n",
    "col = \"response\"\n",
    "df = pd.read_excel(path, na_filter=False, dtype={col: str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Subscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we consider the length of a response by measuring the number of characters. (Note that counting the number of sentences was also considered, but this ended up being too similar to the rank and including it greatly weakened the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len_char'] = df[col].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response Sentence Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use BERT to score the similarity of sentences in a given response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Savannah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Savannah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Savannah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Savannah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Savannah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Savannah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model_sen = SentenceTransformer('bert-base-nli-stsb-mean-tokens')\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def similarity(res):\n",
    "    \n",
    "    # Split response into sentences\n",
    "    res_split = nltk.sent_tokenize(res)\n",
    "    \n",
    "    # Embed each sentence\n",
    "    res_embed = model_sen.encode(res_split)\n",
    "    \n",
    "    # Get the rank of the response embedding matrix\n",
    "    # where each column is a different sentence\n",
    "    rank = np.linalg.matrix_rank(np.transpose(res_embed))\n",
    "    \n",
    "    # Too few sentences to do any comparison\n",
    "    if len(res_split) < 2:\n",
    "        return 0,0,0,0,rank\n",
    "    \n",
    "    # Compare combinations of sentences\n",
    "    # Responses generally have few enough sentences that this is reasonable\n",
    "    sim = [1 - cosine(c[0], c[1]) for c in combinations(res_embed,2)]\n",
    "    \n",
    "    # Return the min, max, mean, median sentence similarities\n",
    "    # as well as the rank and number of sentences\n",
    "    return np.amin(sim), np.amax(sim), np.mean(sim), np.median(sim), rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function and unpack results\n",
    "res = df[col].apply(similarity)\n",
    "df['min']     = [r[0] for r in res]\n",
    "df['max']     = [r[1] for r in res]\n",
    "df['mean']    = [r[2] for r in res]\n",
    "df['median']  = [r[3] for r in res]\n",
    "df['rank']    = [r[4] for r in res]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will use BERT again to determine if a given response discusses certain topics. For a more detailed explanation of our BERT-contextualized keyword searching method, read through the \"LongResponse_Filtering\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "model.eval()\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\n",
    "def get_token_embeddings(text):\n",
    "    \n",
    "    # Tokenize the text\n",
    "    split_text = text.split(\". \")\n",
    "    marked_text = \"[CLS] \" + \" [SEP] \".join(split_text) + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)[:512] # Truncate if longer than 512\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "    # Mark tokens belonging to a sentence\n",
    "    segment_ids = [0]*len(tokenized_text)\n",
    "    is_zero = True\n",
    "    for i in range(len(tokenized_text)):\n",
    "        segment_ids[i] = 0 if is_zero else 1\n",
    "        if tokenized_text[i] == \"[SEP]\":\n",
    "            is_zero = not is_zero\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segment_ids])\n",
    "\n",
    "    # Run through BERT\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    # Adjust\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "    # Get token vectors\n",
    "    token_vecs_sum = []\n",
    "    for token in token_embeddings:\n",
    "        sum_vec = torch.sum(token[-4:], dim=0)\n",
    "        token_vecs_sum.append(sum_vec)\n",
    "    \n",
    "    return token_vecs_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track the number of words in a given text that have\n",
    "#   a high similarity to at least one keyword.\n",
    "# Also track the highest similarity scores\n",
    "\n",
    "# df: Dataframe\n",
    "# column: column to consider for labeling\n",
    "# label: name of column to store results in\n",
    "# keys: keyword dictionary\n",
    "# thresh: similarity threshold\n",
    "def label_topic(df, column, label, keys, thresh):\n",
    "\n",
    "    # Initialize/Reset column\n",
    "    df[label] = 0\n",
    "    df[label+\"_score\"] = float(\"-inf\")\n",
    "    \n",
    "    # Track tokens that matched to keywords\n",
    "    token_matches = []\n",
    "    \n",
    "    # Search\n",
    "    for i in range(len(df)):\n",
    "        best_sim = float(\"-inf\")\n",
    "        embed = get_token_embeddings(df[column][i])\n",
    "        for j in range(len(embed)):\n",
    "            for k in keys:\n",
    "                sim = 1 - cosine(embed[j], k['embed'])\n",
    "                if sim > best_sim:\n",
    "                    best_sim = sim\n",
    "                if sim >= thresh:\n",
    "                    df.at[i, label] += 1\n",
    "                    \n",
    "                    # Get the token that matched to a keyword\n",
    "                    split_text = df[column][i].split(\". \")\n",
    "                    marked_text = \"[CLS] \" + \" [SEP] \".join(split_text) + \" [SEP]\"\n",
    "                    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "                    token_matches.append((tokenized_text[j], k['text']))\n",
    "                    \n",
    "                    break\n",
    "        \n",
    "        df.at[i, label+\"_score\"] = best_sim\n",
    "        \n",
    "        # Track progress\n",
    "        #if i%100==0:\n",
    "        #    print(i,\"/\",len(df))\n",
    "                    \n",
    "    return token_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some topics have been predetermined to be particularly interesting or uninteresting for the prosepective audience. First, we will consider the interesting topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('##es', 'negro soldier'), ('white', 'negro soldier'), ('northern', 'negro soldier'), ('##s', 'negro soldier'), ('whites', 'negro soldier'), ('colored', 'negro soldier'), ('south', 'negro soldier'), ('north', 'negro soldier'), ('tough', 'negro soldier'), ('color', 'negro soldier'), ('white', 'the white man'), ('negro', 'negro soldier'), ('cattle', 'the white man'), ('southern', 'negro soldier'), ('soldiers', 'negro soldier'), ('chinese', 'negro soldier')}\n"
     ]
    }
   ],
   "source": [
    "# Topic 1: Race\n",
    "keys_race = [\n",
    "    {\"text\": \"negro soldier\", \"idx\": 1, \"embed\": None},\n",
    "    {\"text\": \"the white man\", \"idx\": 2, \"embed\": None}\n",
    "]\n",
    "\n",
    "for k in keys_race:\n",
    "    embed = get_token_embeddings(k['text'])\n",
    "    k['embed'] = embed[k['idx']]\n",
    "    \n",
    "    \n",
    "token_matches = label_topic(df, col, 'topic_race', keys_race, 0.5)\n",
    "print(set(token_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('married', 'woman'), ('wife', 'woman'), ('women', 'woman')}\n"
     ]
    }
   ],
   "source": [
    "# Topic 2: Gender\n",
    "keys_gender = [\n",
    "    {\"text\": \"woman\", \"idx\": 1, \"embed\": None}\n",
    "]\n",
    "\n",
    "man_embed = get_token_embeddings(\"man\")[1]\n",
    "for k in keys_gender:\n",
    "    embed = get_token_embeddings(k['text'])\n",
    "    k['embed'] = embed[k['idx']] - (np.dot(embed[k['idx']], man_embed) / np.dot(man_embed, man_embed)) * man_embed\n",
    "    \n",
    "token_matches = label_topic(df, col, 'topic_gender', keys_gender, 0.3)\n",
    "print(set(token_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Expand the list of topics as requested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will consider the uninteresting topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('question', 'too many questions'), ('ideas', 'too many questions'), ('question', 'this is a good questionnaire'), ('questions', 'this is a good questionnaire'), ('questions', 'too many questions'), ('asked', 'too many questions'), ('##naire', 'this is a good questionnaire')}\n"
     ]
    }
   ],
   "source": [
    "# Topic 1: Survey\n",
    "keys_survey = [\n",
    "    {\"text\": \"this is a good questionnaire\", \"idx\": 5, \"embed\": None},\n",
    "    {\"text\": \"too many questions\", \"idx\": 3, \"embed\": None},\n",
    "    {\"text\": \"questions about\", \"idx\": 1, \"embed\": None},\n",
    "]\n",
    "\n",
    "for k in keys_survey:\n",
    "    embed = get_token_embeddings(k['text'])\n",
    "    k['embed'] = embed[k['idx']]\n",
    "    \n",
    "\n",
    "token_matches = label_topic(df, col, 'topic_survey', keys_survey, 0.6)\n",
    "print(set(token_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('no', 'nothing to add'), ('comments', 'no comments'), ('none', 'I have none')}\n"
     ]
    }
   ],
   "source": [
    "# Topic 2: \"No comments\"\n",
    "keys_comment = [\n",
    "    {\"text\": \"I have nothing else to say\", \"idx\": 3, \"embed\": None},\n",
    "    {\"text\": \"no comments\", \"idx\": 2, \"embed\": None},\n",
    "    {\"text\": \"nothing to add\", \"idx\": 1, \"embed\": None},\n",
    "    {\"text\": \"I have none\", \"idx\": 3, \"embed\": None},\n",
    "]\n",
    "\n",
    "for k in keys_comment:\n",
    "    embed = get_token_embeddings(k['text'])\n",
    "    k['embed'] = embed[k['idx']]\n",
    "    \n",
    "\n",
    "token_matches = label_topic(df, col, 'topic_comment', keys_comment, 0.70)\n",
    "print(set(token_matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response Clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clarity(res):\n",
    "    if res.count(\"unclear\") == 0:\n",
    "        return 0\n",
    "    return res.count(\"unclear\") / len(res.split())\n",
    "\n",
    "df['clarity'] = df[col].apply(clarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interest Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use these results along with predetermined answers as to whether or not a response is interesting to construct a model for scoring the interest of a resposne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab rows for training\n",
    "A = df[[\"len_char\", \"min\", \"max\", \"mean\", \"median\", \"rank\", \"topic_survey\",\n",
    "        \"topic_survey_score\", \"topic_comment\", \"topic_comment_score\", \"clarity\"]]\n",
    "b = df[[\"interest\"]] # predetermined interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2cfd4df14a8>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot singular values of A\n",
    "U,S,Vt = np.linalg.svd(A, full_matrices=False)\n",
    "plt.semilogy(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_char:            0.0005499328530886769\n",
      "min:                 0.17943940546253914\n",
      "max:                 -0.28931352264366167\n",
      "mean:                1.468063223740845\n",
      "median:              -1.2308136602304747\n",
      "rank:                0.024345777632150265\n",
      "topic_survey:        0.11086410189840624\n",
      "topic_survey_score:  -0.4000235699670328\n",
      "topic_comment:       -0.08412383628239575\n",
      "topic_comment_score: 0.27711083687464166\n",
      "clarity:             -0.42591282694257143\n"
     ]
    }
   ],
   "source": [
    "# Solve: Ax = b\n",
    "x = (Vt.T)*(1/S)@(U.T@b)\n",
    "\n",
    "print(\"len_char:           \", x.iloc[ 0]['interest'])\n",
    "print(\"min:                \", x.iloc[ 1]['interest'])\n",
    "print(\"max:                \", x.iloc[ 2]['interest'])\n",
    "print(\"mean:               \", x.iloc[ 3]['interest'])\n",
    "print(\"median:             \", x.iloc[ 4]['interest'])\n",
    "print(\"rank:               \", x.iloc[ 5]['interest'])\n",
    "print(\"topic_survey:       \", x.iloc[ 6]['interest'])\n",
    "print(\"topic_survey_score: \", x.iloc[ 7]['interest'])\n",
    "print(\"topic_comment:      \", x.iloc[ 8]['interest'])\n",
    "print(\"topic_comment_score:\", x.iloc[ 9]['interest'])\n",
    "print(\"clarity:            \", x.iloc[10]['interest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each entry in \"x\" can be modified to further fine-tune results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.iloc[10]['interest'] = -1.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product of a vector of subscores with x gives the interest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(r):\n",
    "    return np.dot([r['len_char'], r['min'], r['max'], r['mean'], \n",
    "                   r['median'], r['rank'], r['topic_survey'], r['topic_survey_score'], \n",
    "                   r['clarity'], r['topic_comment'], r['topic_comment_score']], x)[0]\n",
    "    \n",
    "df['interest_score'] = df.apply(score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to excel\n",
    "df.to_excel(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Interest Function to Other Surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interest_score(path, col, encoding = 'cp1252'):\n",
    "    df = pd.read_csv(path, na_filter=False, dtype={col: str}, encoding=encoding)\n",
    "    \n",
    "    df['len_char'] = df[col].apply(len)\n",
    "    \n",
    "    res = df[col].apply(similarity)\n",
    "    df['min']     = [r[0] for r in res]\n",
    "    df['max']     = [r[1] for r in res]\n",
    "    df['mean']    = [r[2] for r in res]\n",
    "    df['median']  = [r[3] for r in res]\n",
    "    df['rank']    = [r[4] for r in res]\n",
    "    \n",
    "    #token_matches = label_topic(df, col, 'topic_race', keys_race, 0.5)\n",
    "    #print(set(token_matches), \"\\n\")\n",
    "    \n",
    "    #token_matches = label_topic(df, col, 'topic_gender', keys_gender, 0.3)\n",
    "    #print(set(token_matches), \"\\n\")\n",
    "    \n",
    "    token_matches = label_topic(df, col, 'topic_survey', keys_survey, 0.6)\n",
    "    print(set(token_matches), \"\\n\")\n",
    "    \n",
    "    token_matches = label_topic(df, col, 'topic_comment', keys_comment, 0.70)\n",
    "    print(set(token_matches))\n",
    "    \n",
    "    df['clarity'] = df[col].apply(clarity)\n",
    "    \n",
    "    df['interest_score'] = df.apply(score, axis=1)\n",
    "    \n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('africa', 'negro soldier'), ('american', 'negro soldier'), ('natives', 'negro soldier'), ('enlisted', 'negro soldier'), ('white', 'the white man'), ('negro', 'negro soldier'), ('southern', 'negro soldier')} \n",
      "\n",
      "{('wives', 'woman'), ('woman', 'woman'), ('wife', 'woman'), ('women', 'woman'), ('men', 'woman'), ('paper', 'woman'), ('married', 'woman'), ('unclear', 'woman')} \n",
      "\n",
      "{('question', 'too many questions'), ('answer', 'too many questions'), ('suggestions', 'too many questions'), ('question', 'this is a good questionnaire'), ('questions', 'this is a good questionnaire'), ('questions', 'too many questions'), ('editorial', 'questions about'), ('articles', 'questions about'), ('facts', 'questions about')} \n",
      "\n",
      "{('suggestions', 'no comments'), ('no', 'nothing to add'), ('none', 'I have none')}\n"
     ]
    }
   ],
   "source": [
    "interest_score(\"../data/Survey_100A_pivoted.csv\", \"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('black', 'negro soldier'), ('##o', 'negro soldier'), ('white', 'negro soldier'), ('yellow', 'the white man'), ('slaves', 'negro soldier'), ('jungle', 'negro soldier'), ('enlisted', 'negro soldier'), ('white', 'the white man'), ('##gger', 'negro soldier'), ('chinese', 'negro soldier')} \n",
      "\n",
      "{('wives', 'woman'), ('woman', 'woman'), ('wife', 'woman'), ('sex', 'woman'), ('men', 'woman'), ('women', 'woman'), ('girl', 'woman'), ('married', 'woman'), ('to', 'woman')} \n",
      "\n",
      "{('question', 'too many questions'), ('ask', 'too many questions'), ('question', 'this is a good questionnaire'), ('questions', 'this is a good questionnaire'), ('questions', 'too many questions'), ('ask', 'questions about')} \n",
      "\n",
      "{('none', 'I have none'), ('remarks', 'no comments'), ('nothing', 'I have nothing else to say')}\n"
     ]
    }
   ],
   "source": [
    "interest_score(\"../data/Survey_100B_pivoted.csv\", \"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_score(\"../data/Survey_100C_pivoted.csv\", \"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('black', 'negro soldier'), ('white', 'negro soldier'), ('yellow', 'the white man'), ('racial', 'negro soldier'), ('enlisted', 'negro soldier')} \n",
      "\n",
      "{('wife', 'woman')} \n",
      "\n",
      "{('concerning', 'questions about'), ('problems', 'too many questions'), ('questions', 'too many questions'), ('question', 'this is a good questionnaire')} \n",
      "\n",
      "{('remarks', 'no comments')}\n"
     ]
    }
   ],
   "source": [
    "interest_score(\"../data/Survey_100D_pivoted.csv\", \"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('black', 'negro soldier'), ('white', 'negro soldier'), ('yellow', 'the white man'), ('slaves', 'negro soldier'), ('jungle', 'negro soldier'), ('enlisted', 'negro soldier'), ('white', 'the white man'), ('negro', 'negro soldier'), ('yankee', 'negro soldier')} \n",
      "\n",
      "{('wives', 'woman'), ('girlfriend', 'woman'), ('woman', 'woman'), ('wife', 'woman'), ('men', 'woman'), ('women', 'woman'), ('couples', 'woman'), ('girl', 'woman'), ('married', 'woman')} \n",
      "\n",
      "{('question', 'too many questions'), ('questions', 'too many questions'), ('question', 'this is a good questionnaire')} \n",
      "\n",
      "{('none', 'I have none')}\n"
     ]
    }
   ],
   "source": [
    "interest_score(\"../data/Survey_100E_pivoted.csv\", \"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('black', 'negro soldier'), ('slave', 'negro soldier'), ('white', 'negro soldier'), ('jungle', 'negro soldier'), ('white', 'the white man')} \n",
      "\n",
      "{('wives', 'woman'), ('woman', 'woman'), ('wife', 'woman'), ('women', 'woman')} \n",
      "\n",
      "{('question', 'too many questions'), ('question', 'this is a good questionnaire'), ('questions', 'this is a good questionnaire'), ('questions', 'too many questions'), ('asked', 'too many questions')} \n",
      "\n",
      "{('none', 'I have none')}\n"
     ]
    }
   ],
   "source": [
    "interest_score(\"../data/Survey_100F_pivoted.csv\", \"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set() \n",
      "\n",
      "{('men', 'woman'), ('women', 'woman')} \n",
      "\n",
      "{('questions', 'this is a good questionnaire'), ('answer', 'too many questions'), ('question', 'this is a good questionnaire')} \n",
      "\n",
      "{('nothing', 'nothing to add'), ('comment', 'no comments'), ('none', 'I have none')}\n"
     ]
    }
   ],
   "source": [
    "interest_score(\"../data/Survey_100G_pivoted.csv\", \"answer\", 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('comments', 'questions about'), ('questioning', 'too many questions'), ('questions', 'too many questions'), ('answers', 'questions about'), ('facts', 'too many questions'), ('answer', 'this is a good questionnaire'), ('question', 'this is a good questionnaire'), ('questions', 'this is a good questionnaire'), ('question', 'questions about'), ('asked', 'too many questions'), ('##naire', 'this is a good questionnaire'), ('asks', 'too many questions'), ('answers', 'too many questions'), ('question', 'too many questions'), ('answer', 'too many questions'), ('questions', 'questions about'), ('ask', 'too many questions'), ('asked', 'questions about'), ('query', 'this is a good questionnaire')} \n",
      "\n",
      "{('nothing', 'nothing to add'), ('comment', 'no comments'), ('none', 'I have none'), ('one', 'I have none'), ('nothing', 'I have nothing else to say'), ('comments', 'no comments')}\n"
     ]
    }
   ],
   "source": [
    "interest_score(\"../data/Survey_32N_pivoted.csv\", \"answer\", 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('comments', 'questions about'), ('questions', 'too many questions'), ('answers', 'questions about'), ('answer', 'this is a good questionnaire'), ('question', 'this is a good questionnaire'), ('questions', 'this is a good questionnaire'), ('question', 'questions about'), ('ask', 'questions about'), ('asked', 'too many questions'), ('##naire', 'this is a good questionnaire'), ('restrictions', 'too many questions'), ('difficulties', 'questions about'), ('ideas', 'too many questions'), ('##der', 'questions about'), ('answers', 'too many questions'), ('examinations', 'too many questions'), ('question', 'too many questions'), ('answer', 'too many questions'), ('questions', 'questions about'), ('ask', 'too many questions')} \n",
      "\n",
      "{('any', 'I have none'), ('comment', 'no comments'), ('none', 'I have none'), ('nothing', 'I have nothing else to say'), ('no', 'nothing to add'), ('comments', 'no comments')}\n"
     ]
    }
   ],
   "source": [
    "interest_score(\"../data/Survey_32W_pivoted.csv\", \"answer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BERT to Embed Multi-Sentence Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To embed individual sentences, we used Sentence-BERT which is a tool extending BERT's base functionality to give \"semantially meaningful sentence embeddings\". The resulting embeddings from this method are comparable using cosine similarity [https://arxiv.org/abs/1908.10084]. \n",
    "\n",
    "In the following section, we demonstrate the use of Sentence-BERT to obtain comparable sentence embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence-BERT Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we would expect similar sentences to have similar embeddings. For each pair of example sentences, we will measure the cosine similarity of their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text\n",
    "example_set_1 = [\n",
    "    ['I like dogs.', 'I love dogs.'],\n",
    "    ['I like dogs.', 'I want a puppy.'],\n",
    "    ['I like dogs.', 'I like cats.'],\n",
    "    ['I like dogs.', 'I want food.'],\n",
    "    ['I like dogs.', 'The hound ran around the yard.'],\n",
    "    ['I like dogs.', \"It snowed today.\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "from textwrap import fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_text(example_set):\n",
    "    \n",
    "    # Initialize table\n",
    "    t = PrettyTable(['Excerpt A', 'Excerpt B', 'Similarity'])\n",
    "    \n",
    "    for e in example_set:\n",
    "        \n",
    "        # Get embeddings for example\n",
    "        embed = model_sen.encode(e)\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        sim = 1 - cosine(embed[0], embed[1])\n",
    "        \n",
    "        # Add results to table\n",
    "        t.add_row([fill(e[0], width=35), fill(e[1], width=35), round(sim,3)])\n",
    "        \n",
    "    # Display table\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_text(example_set_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Multi-Sentence Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the \"LongResponse_Embedding\" notebooks, different methods of embedding responses that may be multi-sentence were considered. For this purpose, we will revist Method 1 which simply passes the full response to the Sentence-BERT encoding function with no special handling.\n",
    "\n",
    "This method is demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_set_2 = [\n",
    "    [\n",
    "        \"The ground was covered in snow. Icicles hung from branches. Snowflakes kept falling.\",\n",
    "        \"Winter has brought the coldest weather. This blizzard seems endless.\"\n",
    "    ],\n",
    "    [\n",
    "        \"Winter has brought the coldest weather. This blizzard seems endless.\",\n",
    "        \"Rain waters the blooming flowers. Spring is finally here.\"\n",
    "    ],\n",
    "    [\n",
    "        \"Winter has brought the coldest weather. This blizzard seems endless.\",\n",
    "        \"The table was filled with delicious food. I couldn't decide which dish to start with.\"\n",
    "    ],\n",
    "    [\n",
    "        \"The table was filled with delicious food. I couldn't decide which dish to start with.\",\n",
    "        \"The smell coming from the stove is mouth-watering.\"\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_text(example_set_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these results, we see that the embeddings of short multi-sentence pieces are still useful. For our purposes, the longest of survey responses are still just a few sentences, so we will assume most embeddings will not be too diluted for use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
